{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91c37e63-8b22-4b2d-8d87-88911adb2147",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "import keras_tuner as kt\n",
    "from tensorflow.compat.v1.metrics import true_positives, false_negatives\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import models, layers\n",
    "from keras.utils import image_dataset_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f507f963-ce91-4753-8414-3ea7d8093e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(file=\"model18.h5\", hist=\"18_history.csv\"):\n",
    "    \n",
    "    # load model and history\n",
    "    \n",
    "    import tensorflow as tf\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    model = tf.keras.models.load_model(file)\n",
    "    history = pd.read_csv(hist)[['loss','binary_accuracy', 'val_loss', 'val_binary_accuracy']]\n",
    "    return model, history\n",
    "\n",
    "def get_data(train_path='images/train/', test_path='images/test/', valid_path='images/val/', size=(256, 256), batch_size=1):\n",
    "    \n",
    "    # preprocess train, test and valid sets\n",
    "    \n",
    "    from keras.utils import image_dataset_from_directory\n",
    "    train = image_dataset_from_directory(directory=train_path,\n",
    "                             label_mode='binary',\n",
    "                             color_mode=\"rgb\",\n",
    "                             image_size=size,\n",
    "                             batch_size=batch_size,\n",
    "                             shuffle=True,\n",
    "                             seed=77)\n",
    "    test = image_dataset_from_directory(directory=test_path,\n",
    "                             color_mode=\"rgb\",\n",
    "                             label_mode='binary',\n",
    "                             image_size=size,\n",
    "                             batch_size=batch_size,\n",
    "                             shuffle=False,\n",
    "                             seed=77)\n",
    "    valid = image_dataset_from_directory(directory=valid_path,\n",
    "                             color_mode=\"rgb\",\n",
    "                             label_mode='binary',\n",
    "                             image_size=size,\n",
    "                             batch_size=batch_size,\n",
    "                             shuffle=False,\n",
    "                             seed=77)\n",
    "    return train, test, valid\n",
    "\n",
    "def evaluate_model(model, n, valid, test):\n",
    "    \n",
    "    pd.DataFrame(model.history.history).plot(figsize=(15,5))\n",
    "    plt.grid(True)\n",
    "    plt.gca().set_ylim(0, 1)\n",
    "    plt.title(f'Model {n} Learning Curves')\n",
    "    plt.show()\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "    print('Test set score')\n",
    "    print()\n",
    "    model.evaluate(test)\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "    print('Validation set score')\n",
    "    print()\n",
    "    model.evaluate(valid)\n",
    "\n",
    "def dim_info(dimension):\n",
    "    print(\"Dimension type: \", type(dimension))\n",
    "    print(\"Dimension length: \", len(dimension))\n",
    "    \n",
    "def garson(A, B):\n",
    "    # reference: https://csiu.github.io/blog/update/2017/03/29/day33.html\n",
    "    \"\"\"\n",
    "    Computes Garson's algorithm\n",
    "    A = matrix of weights of input-hidden layer (rows=input & cols=hidden)\n",
    "    B = vector of weights of hidden-output layer\n",
    "    \"\"\"\n",
    "    B = np.diag(B)\n",
    "\n",
    "    # connection weight through the different hidden node\n",
    "    cw = np.dot(A, B)\n",
    "    cw = cw[1]\n",
    "    # weight through node (axis=0 is column; sum per input feature)\n",
    "    cw_h = abs(cw).sum(axis=0)\n",
    "\n",
    "    # relative contribution of input neuron to outgoing signal of each hidden neuron\n",
    "    # sum to find relative contribution of input neuron\n",
    "    rc = np.divide(abs(cw), abs(cw_h))\n",
    "    rc = rc.sum(axis=1)\n",
    "\n",
    "    # normalize to 100% for relative importance\n",
    "    ri = rc / rc.sum()\n",
    "    return(ri)\n",
    "\n",
    "def images_to_arrays(folder_path):\n",
    "    X = []\n",
    "    y = []\n",
    "    for class_folder in os.listdir(folder_path):\n",
    "        class_path = os.path.join(folder_path, class_folder)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "        class_label = class_folder  # Assign the class folder name as the label\n",
    "        for filename in os.listdir(class_path):\n",
    "            img_path = os.path.join(class_path, filename)\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is not None:\n",
    "                img = cv2.resize(img, (256, 256))  # Resize the image\n",
    "                img_array = np.array(img, dtype=np.float32)  # Convert array values to float\n",
    "                X.append(img_array)\n",
    "                y.append(class_label)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ec81ee4b-8620-43ed-b5ed-65971bd5d989",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyHyperModel(kt.HyperModel):\n",
    "    def build(self, hp):\n",
    "        model = keras.Sequential()\n",
    "        model.add(layers.Rescaling(1./255, input_shape=(256, 256, 3))) # input\n",
    "        model.add(layers.MaxPooling2D(pool_size=2)) # maxpooling 1\n",
    "        model.add(layers.Conv2D(64, kernel_size=2, kernel_regularizer=l2(0.01), activation=\"relu\")) # hidden 1\n",
    "        model.add(layers.MaxPooling2D(pool_size=2)) # maxpooling 2\n",
    "        model.add(layers.Conv2D(64, kernel_size=2, kernel_regularizer=l2(0.01), activation=\"relu\")) # hidden 2\n",
    "        model.add(layers.MaxPooling2D(pool_size=2)) # maxpooling 3\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dropout(hp.Choice('rate',[0.5,0.6])))\n",
    "        model.add(layers.Dense(1, activation=\"sigmoid\")) # output\n",
    "        model.compile(optimizer=Adam(learning_rate=0.0017),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['binary_accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eaa65703-6f50-4174-bd2a-48967e58fde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = images_to_arrays(\"images/train\")\n",
    "X_valid, y_valid = images_to_arrays(\"images/val\")\n",
    "\n",
    "y_train[y_train == 'healthy'] = 0\n",
    "y_train[y_train == 'sick'] = 1\n",
    "y_train = y_train.astype('float32')\n",
    "\n",
    "y_valid[y_valid == 'healthy'] = 0\n",
    "y_valid[y_valid == 'sick'] = 1\n",
    "y_valid = y_valid.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcdc29c-709d-45f2-b3ea-69112cd9c0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test, y_test = images_to_arrays(\"images/train\")\n",
    "\n",
    "# y_test[y_test == 'healthy'] = 0\n",
    "# y_test[y_test == 'sick'] = 1\n",
    "# y_test = y_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d63cad01-cfd6-41de-9165-05a40601b8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16930 files belonging to 2 classes.\n",
      "Found 2115 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train = image_dataset_from_directory(directory='images/train/',\n",
    "                             label_mode='binary',\n",
    "                             color_mode=\"rgb\",\n",
    "                             image_size=(256, 256),\n",
    "                             shuffle=True)\n",
    "valid = image_dataset_from_directory(directory='images/val/',\n",
    "                             color_mode=\"rgb\",\n",
    "                             label_mode='binary',\n",
    "                             image_size=(256, 256),\n",
    "                             shuffle=False,\n",
    "                             seed=77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c07488c3-087b-4def-b9e2-d61be51d4341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Tuner from .\\untitled_project\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner_gs = kt.GridSearch(\n",
    "    MyHyperModel(),\n",
    "    objective='val_loss',\n",
    "    max_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0604973e-aa3b-4240-ac18-1bbac350d2d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 08m 29s]\n",
      "val_loss: 0.41179102659225464\n",
      "\n",
      "Best val_loss So Far: 0.4015653729438782\n",
      "Total elapsed time: 00h 57m 29s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "# 1st gs\n",
    "tuner_gs.search(train, epochs=3, shuffle=True, validation_data=valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "033d7324-d21a-421c-954d-72c380f3089d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_model_1 = tuner_gs.get_best_models()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a520361-78c1-4432-8319-5ff6d6849c39",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in .\\untitled_project\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_loss\", direction=\"min\")\n",
      "\n",
      "Trial 06 summary\n",
      "Hyperparameters:\n",
      "pool_size: 2\n",
      "filters: 64\n",
      "kernel_size: 2\n",
      "rate: 0.5\n",
      "learning_rate: 0.0017\n",
      "Score: 0.4015653729438782\n",
      "\n",
      "Trial 08 summary\n",
      "Hyperparameters:\n",
      "pool_size: 2\n",
      "filters: 64\n",
      "kernel_size: 3\n",
      "rate: 0.5\n",
      "learning_rate: 0.0017\n",
      "Score: 0.40299567580223083\n",
      "\n",
      "Trial 04 summary\n",
      "Hyperparameters:\n",
      "pool_size: 2\n",
      "filters: 32\n",
      "kernel_size: 4\n",
      "rate: 0.5\n",
      "learning_rate: 0.0017\n",
      "Score: 0.4042208194732666\n",
      "\n",
      "Trial 00 summary\n",
      "Hyperparameters:\n",
      "pool_size: 2\n",
      "filters: 32\n",
      "kernel_size: 2\n",
      "rate: 0.5\n",
      "learning_rate: 0.0017\n",
      "Score: 0.40968018770217896\n",
      "\n",
      "Trial 09 summary\n",
      "Hyperparameters:\n",
      "pool_size: 2\n",
      "filters: 64\n",
      "kernel_size: 3\n",
      "rate: 0.6\n",
      "learning_rate: 0.0017\n",
      "Score: 0.41179102659225464\n",
      "\n",
      "Trial 07 summary\n",
      "Hyperparameters:\n",
      "pool_size: 2\n",
      "filters: 64\n",
      "kernel_size: 2\n",
      "rate: 0.6\n",
      "learning_rate: 0.0017\n",
      "Score: 0.41249334812164307\n",
      "\n",
      "Trial 01 summary\n",
      "Hyperparameters:\n",
      "pool_size: 2\n",
      "filters: 32\n",
      "kernel_size: 2\n",
      "rate: 0.6\n",
      "learning_rate: 0.0017\n",
      "Score: 0.4131811559200287\n",
      "\n",
      "Trial 05 summary\n",
      "Hyperparameters:\n",
      "pool_size: 2\n",
      "filters: 32\n",
      "kernel_size: 4\n",
      "rate: 0.6\n",
      "learning_rate: 0.0017\n",
      "Score: 0.41717246174812317\n",
      "\n",
      "Trial 02 summary\n",
      "Hyperparameters:\n",
      "pool_size: 2\n",
      "filters: 32\n",
      "kernel_size: 3\n",
      "rate: 0.5\n",
      "learning_rate: 0.0017\n",
      "Score: 0.4180074632167816\n",
      "\n",
      "Trial 03 summary\n",
      "Hyperparameters:\n",
      "pool_size: 2\n",
      "filters: 32\n",
      "kernel_size: 3\n",
      "rate: 0.6\n",
      "learning_rate: 0.0017\n",
      "Score: 0.4218902587890625\n"
     ]
    }
   ],
   "source": [
    "tuner_gs.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902fe1fd-e491-408d-855b-12d079b3d1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters:\n",
    "# pool_size: 2\n",
    "# filters: 64\n",
    "# kernel_size: 2\n",
    "# rate: 0.5\n",
    "# learning_rate: 0.0017\n",
    "# Score: 0.4015653729438782"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fd9ce6-b3fe-463e-a1ce-a773b242f04a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2nd gs\n",
    "tuner_gs2 = kt.GridSearch(\n",
    "    MyHyperModel(),\n",
    "    objective='val_loss',\n",
    "    max_trials=10)\n",
    "tuner_gs2.search(train, epochs=3, shuffle=True, validation_data=valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9ea38d91-87c5-4e4f-a92c-237bf9aae541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 Complete [00h 07m 08s]\n",
      "val_loss: 0.41039571166038513\n",
      "\n",
      "Best val_loss So Far: 0.39599522948265076\n",
      "Total elapsed time: 00h 14m 11s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "# 3nd gs\n",
    "tuner_gs3 = kt.GridSearch(\n",
    "    MyHyperModel(),\n",
    "    objective='val_loss',\n",
    "    max_trials=10)\n",
    "tuner_gs3.search(train, epochs=3, shuffle=True, validation_data=valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4022389-324b-46a6-9f60-a32f7745150e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters:\n",
    "# rate: 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b47d06ee-15cb-45b7-b8be-747c426a4866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in .\\untitled_project\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_loss\", direction=\"min\")\n",
      "\n",
      "Trial 00 summary\n",
      "Hyperparameters:\n",
      "rate: 0.5\n",
      "Score: 0.39599522948265076\n",
      "\n",
      "Trial 01 summary\n",
      "Hyperparameters:\n",
      "rate: 0.6\n",
      "Score: 0.41039571166038513\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n"
     ]
    }
   ],
   "source": [
    "tuner_gs3.results_summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
